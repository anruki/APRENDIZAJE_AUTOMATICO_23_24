{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv0UorTVdUhz"
      },
      "source": [
        "### Grupo B04\n",
        "### Miguel Egido Morales, Alfredo Robledano Abasolo, Ana Robledano Abasolo\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWbYb_Ejqlms"
      },
      "source": [
        "# P1 AA Configuración y Entrenamiento de una Red de Neuronas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYK5LlXYszma"
      },
      "source": [
        "Utilizaremos la **biblioteca Python Keras** para **clasificar** artículos de ropa.\n",
        "\n",
        "**PROBLEMA:**\n",
        "- Clasificación de imágenes en escala de grises de prendas de ropa (28 x 28 píxeles) en sus 10 categorías (de 0 a 9, guardadas en etiquetas).\n",
        "- Usaremos 60K imágenes de entrenamiento y más de 10K imágenes de prueba\n",
        "- El conjunto de datos MNIST está precargado en Keras en la forma de un conjunto de cuatro matrices Numpy\n",
        "- Algunas muestras\n",
        "- Tenemos las siguientes categorías o **clases** del problema de clasificación de ropa: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot.\n",
        "- Los \"puntos de datos\" son **muestras**\n",
        "- La clase asociado a una muestra específica se llama **etiqueta**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt69U75udUh1"
      },
      "source": [
        "Importamos el paquete tensorflow que contiene a la librería keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZRjUdLDqlmt",
        "outputId": "c308bae6-ab5a-46f0-e753-1b7b91fbd57d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 363
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__ >= '2.0.0'  # Comprobamos que estamos usando al menos la versión 2.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifOEj4QTFDju"
      },
      "source": [
        "El módulo keras.datasets contiene un dataset con imágenes de ropa que usaremos para este proyecto.\\\n",
        "Las imágenes se encuentran convenientemente etiquetadas y en formato mnist.\\\n",
        "A continuación almacenamos en memoria las imágenes de entrenamiento  e imágenes de test (junto con sus etiquetas)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA0GDH69qlmu",
        "outputId": "3090878c-ed2b-4ea1-e3f8-69a983872ebc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> (60000, 28, 28) (60000,)\n",
            "<class 'numpy.ndarray'> (10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "print(type(train_images), train_images.shape, train_labels.shape)\n",
        "print(type(test_images), test_images.shape, test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7MkuUAZqlmv",
        "outputId": "cbbc5025-b1ef-44ab-c4d0-d51963575558"
      },
      "source": [
        "Observamos que train_images y test_images son numpy.arrays de 3 dimensiones.\\\n",
        "60_000 imágenes de 28x28 pixels para el entrenamiento (60_000 etiquetas).\\\n",
        "10_000 imágenes de 28x28 pixels para test (10_000 etiquetas)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lWXf4WHdUh3"
      },
      "source": [
        "Comprobamos que las etiquetas van de 0 a 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLk8C6abdUh3",
        "outputId": "1117ec35-bfb4-482b-d5c0-167a0946aa3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
          ]
        }
      ],
      "source": [
        "print(set(train_labels))\n",
        "print(set(test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rp_ygXtzdUh3"
      },
      "source": [
        "Echemos un vistazo a alguna imagen del set de entrenamiento (son numpy arrays 2D)\\\n",
        "Por ejemplo la número 30_000\\\n",
        "Para ello importamos numpy, de forma que podamos cambiar las opciones de impresión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fi2DmUJ5qlmv",
        "outputId": "cc6ce79d-8eb6-4874-884c-933350b7a91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0 118 204 181 175 213 199 168 197 111   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 173 225 185 179 225 158 142 227 173   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 170 229 226 226 233 151 167 234 158   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 194 222 212 226 222 240 218 230 163   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 198 222 210 207 211 207 208 231 147   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 188 220 209 210 211 215 208 230 144   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 183 232 214 220 212 220 213 239 158   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 183 232 217 216 215 219 216 238 160   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 185 231 218 221 215 218 214 238 170   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 188 233 215 220 219 219 216 238 169   0   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 169 240 219 221 222 228 214 243 114   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 128 255 214 218 206 205 225 233  53   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 200 229 218 221 219 211 217 228 204   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  34 230 214 217 216 218 218 220 217 231  42   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  94 236 213 219 219 218 215 219 213 234 110   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 167 234 212 218 218 219 212 225 215 231 170   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 200 230 213 216 218 221 211 224 214 228 213   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 192 228 213 216 218 222 213 224 215 221 200   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 202 225 216 214 219 215 219 225 215 219 208   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 215 224 214 215 221 213 217 220 215 216 216   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  26 232 214 218 213 226 212 216 225 215 211 224  27   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  59 234 214 220 214 225 211 213 227 216 212 228  51   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  67 233 214 221 213 227 209 215 228 216 211 228  56   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  92 234 215 219 215 226 208 214 227 215 211 225  42   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 116 236 215 218 211 230 213 212 229 215 211 228  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 140 231 218 221 221 236 204 219 224 221 219 227 132   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 107 200 193 205 194 217 213 218 248 202 172 227 105   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  21 108 142 146 125 173 141  94 152 154  89   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=2, suppress=True, linewidth=145)\n",
        "print(np.matrix(train_images[30_000]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_bUss0edUh4"
      },
      "source": [
        "A simple vista ningún problema\\\n",
        "Los valores de la matriz 2D asociada a la imagen están entre 0 y 255.\\\n",
        "Podemos ver su etiqueta asociada, 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a9GvqdTqlmv",
        "outputId": "ef2a9c0f-da1a-4f88-f127-e0496329d757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "print(train_labels[30_000])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iUyaT4FdUh4"
      },
      "source": [
        "Viendo la documentación sabemos que se trata de un vestido por ser el valor 3. (3: Dress)\\\n",
        "No obstante podemos usar el paquete matplotlib para ver como es la imagen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "vq3OWBIgqlmv",
        "outputId": "b3c7327a-4e89-439a-8ee7-1f72979cb3b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "ropa = train_images[30000]\n",
        "plt.imshow(ropa, cmap=plt.cm.binary) # el num más bajo se pone en color blanco, y el más alto en negro\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cZYNDGzdUh4"
      },
      "source": [
        "Abrimos también una imagen del set de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "ylVHZ8aYqlmw",
        "outputId": "b7fe3cf0-89e8-42bf-a5eb-65ebdea7529a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt # TODO importar mnist, como lo hace el profe\n",
        "ropa = test_images[0]\n",
        "plt.imshow(ropa, cmap=plt.cm.binary) # Veamos el elemento 0 del set de tests y pintémoslo con matplotlib\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNu3uJWTdUh4"
      },
      "source": [
        "Un zapato, no cabe duda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmJs2BINqlmw",
        "outputId": "77d84951-6952-4bcf-ab66-71438bbd6726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ],
      "source": [
        "print(test_labels[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcVJhxOxdUh5"
      },
      "source": [
        "Así lo indica su etiqueta (9: shoe)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVDGHuPNvTqL"
      },
      "source": [
        "La función de keras keras.layers.Flatten() nos podría ser útil para aplanar la entrada .... (falta info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzT5-LModUh5"
      },
      "source": [
        "## Cuestiones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU9pZNHbXARm"
      },
      "source": [
        "# Normalización de los datos\n",
        "para facilitar que converja el proceso de entrenamiento preparamos los datos de imagen con alguna transformación. Los tensores transformados tienen la misma cantidad de datos total que el tensor inicial.\n",
        "\n",
        "Utilizaremos la función flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMMrQ03KXVpH",
        "outputId": "4656c266-8dd1-4528-9dba-ac9b37345a6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "[[  0   0   0   0   0   0   0   0   1   1   0   0 120 131  91 147  30   0   0   1   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   1   3   0   0   0   0 251 199 172 195 152   0   0   0   0   3   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  43 124 193 166 239 255 216 172 228 126  61   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  96 167 155 159 171 178 211 215 210 196 189 158 164 159 108   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  83 157 131 117 120 148 148 145 178 159 174 160 123 132 142 172  38   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 159 128 118 120 122 112  93 124 161 109 128 128 129 146 138 167 122   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 171 135 120 114 118 119 107 125 123 117 124 124 119 145 147 166 148   0   0   0   0   0]\n",
            " [  0   0   0   0   0   4 171 138 126 120 117 118 102 122 145 111 120 122 120 152 154 155 170   0   0   0   0   0]\n",
            " [  0   0   0   0   0  31 170 129 138 125 113 106 103 118 137 108 135 130 158 182 138 143 186   0   0   0   0   0]\n",
            " [  0   0   0   0   0  58 163 114 137 143 119 103 100 109 118 109 129 134 172 181 131 136 190   0   0   0   0   0]\n",
            " [  0   0   0   0   0  76 160 113 141 148 128 111 101 116 137 111 131 142 167 183 136 120 186  12   0   0   0   0]\n",
            " [  0   0   0   0   0 100 148 108 147 147 134 120 105 116 131 116 136 137 165 192 137 113 187  30   0   0   0   0]\n",
            " [  0   0   0   0   0 114 143 108 158 147 130 125 106 114 122 119 129 134 160 196 136 109 182  51   0   0   0   0]\n",
            " [  0   0   0   0   0 120 140 117 151 148 131 124 109 120 143 120 130 128 159 188 111 108 178  66   0   0   0   0]\n",
            " [  0   0   0   0   0 125 129 128 112 145 140 122 113 118 134 117 132 128 166 157  91 120 170  74   0   0   0   0]\n",
            " [  0   0   0   0   0 126 123 138  74 140 143 124 111 112 126 120 130 129 175 120  88 128 164  91   0   0   0   0]\n",
            " [  0   0   0   0   0 124 123 157  45 145 143 124 113 119 148 122 131 129 183  90  73 137 155  99   0   0   0   0]\n",
            " [  0   0   0   0   0 118 122 167   0 143 149 122 112 118 137 116 132 126 183  73  50 152 147 101   0   0   0   0]\n",
            " [  0   0   0   0   0 111 128 164   0 142 151 122 111 117 132 120 136 125 182  90  18 164 145 107   0   0   0   0]\n",
            " [  0   0   0   0   0 109 132 158   0 146 148 120 108 125 157 120 136 131 176 111   0 164 143 118   0   0   0   0]\n",
            " [  0   0   0   0   0 111 141 140   0 148 149 120 114 123 137 124 137 131 171 135   0 157 147 125   0   0   0   0]\n",
            " [  0   0   0   0   0 111 154 111   0 155 148 118 116 124 143 123 131 129 167 155   0 129 157 129   0   0   0   0]\n",
            " [  0   0   0   0   0 109 155  87   0 157 145 119 117 126 154 126 130 123 161 160   0  97 163 130   0   0   0   0]\n",
            " [  0   0   0   0   0 124 142  54   0 149 141 119 119 124 136 129 126 120 153 175   0  76 145 137   0   0   0   0]\n",
            " [  0   0   0   0   0 136 151  47   0 149 137 119 118 126 143 132 130 123 153 172   0  66 148 154   0   0   0   0]\n",
            " [  0   0   0   0   0 109 174  48   0 154 138 119 117 124 138 130 129 125 159 167   0  58 174 128   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  85 182 147 136 143 158 146 148 153 199  70   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  26  54  72  83  96  85  80  61  14   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "# train_images = train_images.reshape((60000, 28 * 28))  # TODO: eliminar esta linea\n",
        "print(train_images.shape)\n",
        "np.set_printoptions(precision=2, suppress=True, linewidth=145)\n",
        "print(np.matrix(train_images[3000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2THPuJzYi0S",
        "outputId": "9d44fb78-97b9-4b55-91d9-c338ca90f196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.47 0.51 0.36 0.58 0.12 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.01 0.   0.   0.   0.   0.98 0.78 0.67 0.76 0.6  0.   0.   0.   0.   0.01 0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.17 0.49 0.76 0.65 0.94 1.   0.85 0.67 0.89 0.49 0.24 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.38 0.65 0.61 0.62 0.67 0.7  0.83 0.84 0.82 0.77 0.74 0.62 0.64 0.62 0.42 0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.33 0.62 0.51 0.46 0.47 0.58 0.58 0.57 0.7  0.62 0.68 0.63 0.48 0.52 0.56 0.67 0.15 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.62 0.5  0.46 0.47 0.48 0.44 0.36 0.49 0.63 0.43 0.5  0.5  0.51 0.57 0.54 0.65 0.48 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.67 0.53 0.47 0.45 0.46 0.47 0.42 0.49 0.48 0.46 0.49 0.49 0.47 0.57 0.58 0.65 0.58 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.02 0.67 0.54 0.49 0.47 0.46 0.46 0.4  0.48 0.57 0.44 0.47 0.48 0.47 0.6  0.6  0.61 0.67 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.12 0.67 0.51 0.54 0.49 0.44 0.42 0.4  0.46 0.54 0.42 0.53 0.51 0.62 0.71 0.54 0.56 0.73 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.23 0.64 0.45 0.54 0.56 0.47 0.4  0.39 0.43 0.46 0.43 0.51 0.53 0.67 0.71 0.51 0.53 0.75 0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.3  0.63 0.44 0.55 0.58 0.5  0.44 0.4  0.45 0.54 0.44 0.51 0.56 0.65 0.72 0.53 0.47 0.73 0.05 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.39 0.58 0.42 0.58 0.58 0.53 0.47 0.41 0.45 0.51 0.45 0.53 0.54 0.65 0.75 0.54 0.44 0.73 0.12 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.45 0.56 0.42 0.62 0.58 0.51 0.49 0.42 0.45 0.48 0.47 0.51 0.53 0.63 0.77 0.53 0.43 0.71 0.2  0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.47 0.55 0.46 0.59 0.58 0.51 0.49 0.43 0.47 0.56 0.47 0.51 0.5  0.62 0.74 0.44 0.42 0.7  0.26 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.49 0.51 0.5  0.44 0.57 0.55 0.48 0.44 0.46 0.53 0.46 0.52 0.5  0.65 0.62 0.36 0.47 0.67 0.29 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.49 0.48 0.54 0.29 0.55 0.56 0.49 0.44 0.44 0.49 0.47 0.51 0.51 0.69 0.47 0.35 0.5  0.64 0.36 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.49 0.48 0.62 0.18 0.57 0.56 0.49 0.44 0.47 0.58 0.48 0.51 0.51 0.72 0.35 0.29 0.54 0.61 0.39 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.46 0.48 0.65 0.   0.56 0.58 0.48 0.44 0.46 0.54 0.45 0.52 0.49 0.72 0.29 0.2  0.6  0.58 0.4  0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.44 0.5  0.64 0.   0.56 0.59 0.48 0.44 0.46 0.52 0.47 0.53 0.49 0.71 0.35 0.07 0.64 0.57 0.42 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.43 0.52 0.62 0.   0.57 0.58 0.47 0.42 0.49 0.62 0.47 0.53 0.51 0.69 0.44 0.   0.64 0.56 0.46 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.44 0.55 0.55 0.   0.58 0.58 0.47 0.45 0.48 0.54 0.49 0.54 0.51 0.67 0.53 0.   0.62 0.58 0.49 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.44 0.6  0.44 0.   0.61 0.58 0.46 0.45 0.49 0.56 0.48 0.51 0.51 0.65 0.61 0.   0.51 0.62 0.51 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.43 0.61 0.34 0.   0.62 0.57 0.47 0.46 0.49 0.6  0.49 0.51 0.48 0.63 0.63 0.   0.38 0.64 0.51 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.49 0.56 0.21 0.   0.58 0.55 0.47 0.47 0.49 0.53 0.51 0.49 0.47 0.6  0.69 0.   0.3  0.57 0.54 0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.53 0.59 0.18 0.   0.58 0.54 0.47 0.46 0.49 0.56 0.52 0.51 0.48 0.6  0.67 0.   0.26 0.58 0.6  0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.43 0.68 0.19 0.   0.6  0.54 0.47 0.46 0.49 0.54 0.51 0.51 0.49 0.62 0.65 0.   0.23 0.68 0.5  0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.33 0.71 0.58 0.53 0.56 0.62 0.57 0.58 0.6  0.78 0.27 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
            " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.1  0.21 0.28 0.33 0.38 0.33 0.31 0.24 0.05 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n"
          ]
        }
      ],
      "source": [
        "train_images = train_images.astype('float32') / 255\n",
        "print(np.matrix(train_images[3000]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alIAz6yMYjcU"
      },
      "outputs": [],
      "source": [
        "test_images = test_images.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tTSAqxNYhY3"
      },
      "source": [
        "Codificaremos categoricamente las etiquetas en one-hot encoding, transformando las etiquetas en un vector de tantos ceros como el número de etiquetas distinta, y que contiene el valor de 1 en el índice que le corresponde al valor de la etiqueta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGqy5GUBYw9r",
        "outputId": "e08229ed-25a1-42df-a2c2-2317fe2726a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 374
        }
      ],
      "source": [
        "# Preparación de las etiquetas\n",
        "import numpy as np\n",
        "from keras import utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "train_labels[30000] # Posición 0 a 9 donde solo la 3 tiene probabilidad 1.\n",
        "# El número 30000 de entrenamiento es un 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmYxDHVEZEUI"
      },
      "source": [
        "En el array de la etiqueta 30000, el 1 está en la posición 3 ya que se trata del índice 3 (Dress)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7SvF5s6dUh5"
      },
      "source": [
        "# 1. Configurar y entrenar los siguientes modelos de red de neuronas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBIhnqmcdUh5"
      },
      "source": [
        "A continuación establecemos los parámetros de configuración solicitados\\\n",
        "Utilizaremos namedtuples como contenedores de las configuraciones\\\n",
        "Nota: Las configuraciones de este tipo recomendaríamos tenerlas en un script aparte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGe7bDl5dUh5",
        "outputId": "7acd246d-aa21-4cfe-b06d-ad13b5683f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Param_RN(neuronas_capa1=10, funcion_activacion='relu', optimizador='sgd')\n"
          ]
        }
      ],
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "# Guardamos las configuraciones en tuplas\n",
        "neuronas_capa1 = (10, 10, 10, 10, 512, 512, 512, 512)\n",
        "funcion_activacion = (\"relu\", \"relu\", \"sigmoid\", \"sigmoid\", \"relu\", \"relu\", \"sigmoid\", \"sigmoid\")\n",
        "optimizador = (\"sgd\", \"rmsprop\", \"sgd\", \"rmsprop\", \"sgd\", \"rmsprop\", \"sgd\", \"rmsprop\")\n",
        "\n",
        "# Usaremos namedtuples como contenedores de las configuraciones anteriores\n",
        "param_rn = namedtuple(\"Param_RN\",\n",
        "                      [\"neuronas_capa1\",\"funcion_activacion\",\"optimizador\"])\n",
        "\n",
        "# Guardamos en una lista las namedtuples\n",
        "rn_configs = [param_rn(*params) for params in zip(neuronas_capa1,\n",
        "                                                  funcion_activacion,\n",
        "                                                  optimizador)]\n",
        "print(rn_configs[0])  # Vemos un ejemplo de que el formato es correcto"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como queremos obtener los mismos resultados para cualquier usuario que ejecute el programa, usamos una seed para inicializar los pesos posteriormente."
      ],
      "metadata": {
        "id": "8XEkTpV-ZPzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Establecer la semilla global\n",
        "seed_value = 42\n",
        "tf.random.set_seed(seed_value)"
      ],
      "metadata": {
        "id": "ZT_tQ9VkZWXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEc03ZbRdUh5"
      },
      "source": [
        "Adicionalmente se utilizará:\n",
        "* función de perdida 'categorical_crossentropy'\n",
        "* métrica de precisión\n",
        "* 5 épocas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkAsMhuXdUh5"
      },
      "source": [
        "**CONSTRUIMOS LA RNA**\n",
        "- **Capa** (**layers**) es el **componente básico de las redes neuronales**. => Es un **filtro** de datos (módulo de procesamiento de datos).Entran datos y salen con una forma más útil para el objetivo del problema a resolver. => **Destilación de datos**\n",
        "\n",
        "El tipo de modelo para nuestras redes será secuencial y utilizaremos 2 capas densas (cada neurona está conectada a todas las demás de esa capa).\n",
        "Las redes constarán de dos capas densas:\n",
        "* **Capa 0** es una capa que convierte el input que son matrices 28x28 a un vector (aplana la matriz a un vector).\n",
        "* **Capa 1** contiene el número de neuronas y su función de activación (ambos especificados en el enunciado)\n",
        "* **Capa 2** contiene 10 neuronas (una para cada tipo de ropa) y función de activación softmax.\n",
        "Esta última capa nos servirá para saber como de bien lo ha hecho la red, al devolvernos una matriz de 10 puntuaciones de probabilidad (sumando 1)\n",
        "\n",
        "La puntuación será la probabilidad de que la imagen pertenezca a una de nuestras clases de 10 tipos de prendas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzV0Wi66AGug",
        "outputId": "e196edbf-3b46-4ac9-c2f6-be834a48e1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_185\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Capa_0 (Flatten)            (None, 784)               0         \n",
            "                                                                 \n",
            " Capa_1 (Dense)              (None, 10)                7850      \n",
            "                                                                 \n",
            " Capa_2 (Dense)              (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7960 (31.09 KB)\n",
            "Trainable params: 7960 (31.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 3.- CONSTRUIMOS LA ARQUITECTURA DE LA RED\n",
        "from keras import models  # importamos de keras las librerías de modelos y de capas (layers)\n",
        "from keras import layers\n",
        "\n",
        "img_shape = train_images.shape[1:]  # Dimensiones entradas (28, 28)\n",
        "networks = []\n",
        "weights_initializer = tf.keras.initializers.GlorotUniform(seed=seed_value) # inicialización de pesos usando GlorotUniform\n",
        "for config in rn_configs:\n",
        "  network = models.Sequential()\n",
        "  # Capa 0 (Convertir el input en 1D)\n",
        "  network.add(layers.Flatten(input_shape=img_shape,\n",
        "                             name='Capa_0'))\n",
        "\n",
        "  # Capa 1 (configuración enunciado)\n",
        "  network.add(layers.Dense(units=config.neuronas_capa1,\n",
        "                           activation=config.funcion_activacion,\n",
        "                           kernel_initializer=weights_initializer, # inicialización de pesos\n",
        "                           name='Capa_1'))\n",
        "\n",
        "  # Capa 2 (10 neuronas y softmax)\n",
        "  network.add(layers.Dense(units=10,\n",
        "                           activation='softmax',\n",
        "                           kernel_initializer=weights_initializer,\n",
        "                           name='Capa_2'))\n",
        "  networks.append(network)\n",
        "\n",
        "# Por ejemplo, vemos la primera network de nuestra lista de networks\n",
        "networks[0].summary()\n",
        "\n",
        "# guardamos los pesos iniciales en una variable\n",
        "initial_weights = [network.get_weights() for network in networks]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos inicializado los pesos aleatoriamente usando Glorot uniform y la seed que hemos definido anteriormente.\n",
        "Para conseguir una convergencia sustancialmente más rápida y una mayor precisión en los resultados, la mejor forma es inicializar los pesos con un inicializador de pesos GlorotNormal o GlorotUniform."
      ],
      "metadata": {
        "id": "n39nSQlgefeq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGNdAEL_EKvg"
      },
      "source": [
        "Observamos que para la primera red neuronal (networks[0]), tenemos un total de 7960 parámetros que se obtienen como resultado de *nº de neuronas x nº de entradas + sesgos* de cada capa ya que las capas son densas.\n",
        "\n",
        "*   **Capa 1:** 10 x 784 + 10 = 7850\n",
        "*   **Capa 2:** 10 x 10 + 10 = 110\n",
        "*   **TOTAL:** 7850 + 110 = 7960"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5s8MCtJRYCz"
      },
      "source": [
        "Para terminar de preparar la red, debemos elegir:\n",
        "- Una **función de pérdida**: utilizaremos la función de pérdida `categorical_crossentropy` que mide la discrepancia entre las predicciones de un modelo y las respuestas reales en problemas de clasificación con múltiples categorías. Calcula la diferencia entre las distribuciones de probabilidad predichas y las verdaderas, utilizando la entropía cruzada como métrica.\n",
        "\n",
        "- Un **optimizador**: dependiendo del caso usaremos los optimizadores `sgd` o `rmsprop`.\n",
        "  \n",
        "\n",
        "1.   SGD (Descenso de Gradiente Estocástico): Actualiza los pesos en dirección opuesta al gradiente de la función de pérdida. \"Estocástico\" significa que utiliza muestras de datos de manera aleatoria para calcular el gradiente, lo que puede ayudar a evitar mínimos locales.\n",
        "2.   RMSprop (Root Mean Square Propagation): Modifica el SGD para adaptarse a tasas de aprendizaje diferentes para cada parámetro. Almacena una media móvil ponderada de los cuadrados de los gradientes anteriores y utiliza esta información para normalizar la tasa de aprendizaje.\n",
        "\n",
        "\n",
        "- **Métricas** para monitorizar durante el entrenamiento y las pruebas. Solo nos preocuparemos por la **precisión** `accuracy` (la fracción de las imágenes que fueron clasificado)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZFKNvdaLKnY"
      },
      "outputs": [],
      "source": [
        "# Cargamos el optimizador, la función de pérdida y las métricas\n",
        "for i, config in enumerate(rn_configs):\n",
        "  networks[i].compile(optimizer=config.optimizador,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy']) # si de cada 10 imágenes acierta 8, tiene un accuracy del 80%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrjL3Y6AVfAx"
      },
      "source": [
        "La función de pérdida crossentropy se utiliza como señal\n",
        "de retroalimentación para aprender los tensores de peso y que la fase de\n",
        "entrenamiento intentará minimizar.\\\n",
        "La reducción de la pérdida se produce mediante el descenso de gradiente\n",
        "estocástico minilote, cuyas reglas exactas están gobernadas por el optimizador\n",
        "'rmsprop'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0viqnuRkZV57"
      },
      "source": [
        "# Entrenamiento de las redes neuronales\n",
        "\n",
        "\n",
        "*   Nº de épocas: Usaremos 5 épocas (la red pasará 5 veces por el conjunto de datos) para\n",
        "separar el entrenamiento en 5 fases, dividir el entrenamiento en épocas es útil para el registro y la evaluación periódica\n",
        "*   Tamaño del lote (batch size): tomamos paquetes de 128 imágenes, para calcular la media de las pérdidas y ajustar los parámetros cada 128 imágenes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya que el tiempo de compilación es alto, hemos creado carpetas con las redes neuronales entrenadas (en `trained_networks`) para no tener que entrenarlas cada vez que se abra el documento. En su lugar, las cargaremos entrenadas con la función load_model y trabajaremos con los resultados obtenidos"
      ],
      "metadata": {
        "id": "9ettHc6yoD0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.engine.functional import network_serialization\n",
        "from keras.models import load_model\n",
        "\n",
        "# Especifica la ruta al archivo del modelo\n",
        "networks_path = 'trained_networks'\n",
        "networks = [] # TODO: revisar tener q inicializar networks o añadir if len(networks) < 9:\n",
        "# Carga el modelo\n",
        "for i in range(8):\n",
        "    model_path = \"/\".join([networks_path, f\"network_{i}\"])\n",
        "    networks.append(load_model(model_path))"
      ],
      "metadata": {
        "id": "OMd0ZI5roPJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos un vector de networks con los 8 casos."
      ],
      "metadata": {
        "id": "FD7YebGsPBE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(networks)"
      ],
      "metadata": {
        "id": "SWxyhQ59PAkG",
        "outputId": "6b93c643-6928-4339-8cbc-d75e4596d551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 380
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opcionalmente se podría ejecutar y continuar con el programa."
      ],
      "metadata": {
        "id": "wxr7WgWLp1HL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "vMFjaqJLCU7u",
        "outputId": "4b61cffe-a001-4e16-9592-02708e5dc5ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 2s 2ms/step - loss: 1.4794 - accuracy: 0.4973\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.8596 - accuracy: 0.6940\n",
            "Epoch 3/5\n",
            "214/469 [============>.................] - ETA: 1s - loss: 0.7448 - accuracy: 0.7369"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-340-ceeb416cabff>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetworks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# esta linea es para entrenar por primera vez para los pesos iniciales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1740\u001b[0m                         ):\n\u001b[1;32m   1741\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1742\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1743\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1744\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    855\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m       (concrete_function,\n\u001b[1;32m    147\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    149\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1348\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_call_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1457\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1458\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for i, network in enumerate(networks):\n",
        "  network.set_weights(initial_weights[i]) # esta linea es para entrenar por primera vez para los pesos iniciales\n",
        "  network.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBKPt5CNbWR8"
      },
      "source": [
        "La red empezará a iterar por lo datos de entrenamiento en minilotes de 128 muestras, 5 veces. En cada iteración, la red computará los gradientes de los pesos en relación con la pérdida en el lote y ajustará los pesos en\n",
        "consecuencia. Tras estas 5 repeticiones, la red habrá realizado 2.345 ajustes de gradiente (469 por repetición), la pérdida será lo bastante baja como para que la red sea capaz de clasificar números escritos a mano con gran exactitud.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yEdnkcjdy3l"
      },
      "source": [
        "# 2. Explicar la salida de la llamada model.summary() de cada uno de los 8 casos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjFsCJv_Nop3",
        "outputId": "c59932b1-53f9-40c3-8e01-f89e89ab1818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 0:\n",
            "Model: \"sequential_97\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Capa_0 (Flatten)            (None, 784)               0         \n",
            "                                                                 \n",
            " Capa_1 (Dense)              (None, 10)                7850      \n",
            "                                                                 \n",
            " Capa_2 (Dense)              (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7960 (31.09 KB)\n",
            "Trainable params: 7960 (31.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 1:\n",
            "Model: \"sequential_98\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Capa_0 (Flatten)            (None, 784)               0         \n",
            "                                                                 \n",
            " Capa_1 (Dense)              (None, 10)                7850      \n",
            "                                                                 \n",
            " Capa_2 (Dense)              (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7960 (31.09 KB)\n",
            "Trainable params: 7960 (31.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 2:\n",
            "Model: \"sequential_99\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Capa_0 (Flatten)            (None, 784)               0         \n",
            "                                                                 \n",
            " Capa_1 (Dense)              (None, 10)                7850      \n",
            "                                                                 \n",
            " Capa_2 (Dense)              (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7960 (31.09 KB)\n",
            "Trainable params: 7960 (31.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 3:\n",
            "Model: \"sequential_100\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Capa_0 (Flatten)            (None, 784)               0         \n",
            "                                                                 \n",
            " Capa_1 (Dense)              (None, 10)                7850      \n",
            "                                                                 \n",
            " Capa_2 (Dense)              (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7960 (31.09 KB)\n",
            "Trainable params: 7960 (31.09 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 4:\n",
            "Model: \"sequential_101\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Capa_0 (Flatten)            (None, 784)               0         \n",
            "                                                                 \n",
            " Capa_1 (Dense)              (None, 512)               401920    \n",
            "                                                                 \n",
            " Capa_2 (Dense)              (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 5:\n",
            "Model: \"sequential_102\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Capa_0 (Flatten)            (None, 784)               0         \n",
            "                                                                 \n",
            " Capa_1 (Dense)              (None, 512)               401920    \n",
            "                                                                 \n",
            " Capa_2 (Dense)              (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 6:\n",
            "Model: \"sequential_103\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Capa_0 (Flatten)            (None, 784)               0         \n",
            "                                                                 \n",
            " Capa_1 (Dense)              (None, 512)               401920    \n",
            "                                                                 \n",
            " Capa_2 (Dense)              (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 7:\n",
            "Model: \"sequential_104\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Capa_0 (Flatten)            (None, 784)               0         \n",
            "                                                                 \n",
            " Capa_1 (Dense)              (None, 512)               401920    \n",
            "                                                                 \n",
            " Capa_2 (Dense)              (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 407050 (1.55 MB)\n",
            "Trainable params: 407050 (1.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, network in enumerate(networks):\n",
        "  print(f\"\\nPARÁMETROS DE LA RED NEURONAL {i}:\")\n",
        "  network.summary()\n",
        "  print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EXPLICACIONES."
      ],
      "metadata": {
        "id": "XHp9AgPs0Abj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*PRIMERA RED NEURONAL*\n",
        "\n",
        "Observamos que para la primera red neuronal (networks[0]), tenemos un total de 7960 parámetros que se obtienen como resultado de nº de neuronas x nº de entradas + sesgos de cada capa ya que las capas son densas.\n",
        "\n",
        "Capa 1: 10 x 784 + 10 = 7850\n",
        "\n",
        "Capa 2: 10 x 10 + 10 = 110\n",
        "\n",
        "TOTAL: 7850 + 110 = 7960\n",
        "\n",
        "*SEGUNDA RED NEURONAL*\n",
        "\n",
        "En la segunda red neuronal (networks[1]), tenemos un total de 7960 parámetros.\n",
        "\n",
        "Capa 1: 10 x 784 + 10 = 7850\n",
        "\n",
        "Capa 2: 10 x 10 + 10 = 110\n",
        "\n",
        "TOTAL: 7850 + 110 = 7960\n",
        "\n",
        "*TERCERA RED NEURONAL*\n",
        "\n",
        "En la tercera red neuronal (networks[2]), tenemos un total de 7960 parámetros.\n",
        "\n",
        "Capa 1: 10 x 784 + 10 = 7850\n",
        "\n",
        "Capa 2: 10 x 10 + 10 = 110\n",
        "\n",
        "TOTAL: 7850 + 110 = 7960\n",
        "\n",
        "*CUARTA RED NEURONAL*\n",
        "\n",
        "En la cuarta red neuronal (networks[3]), tenemos un total de 7960 parámetros.\n",
        "\n",
        "Capa 1: 10 x 784 + 10 = 7850\n",
        "\n",
        "Capa 2: 10 x 10 + 10 = 110\n",
        "\n",
        "TOTAL: 7850 + 110 = 7960\n",
        "\n",
        "*QUINTA RED NEURONAL*\n",
        "\n",
        "En la quinta red neuronal (networks[4]), tenemos un total de 407050 parámetros.\n",
        "\n",
        "Capa 1: 512 x 784 + 512 = 401920\n",
        "\n",
        "Capa 2: 512 x 10 + 512 = 5130\n",
        "\n",
        "TOTAL: 401920 + 5130 = 407050\n",
        "\n",
        "*SEXTA RED NEURONAL*\n",
        "\n",
        "En la sexta red neuronal (networks[5]), tenemos un total de 407050 parámetros.\n",
        "\n",
        "Capa 1: 512 x 784 + 512 = 401920\n",
        "\n",
        "Capa 2: 512 x 10 + 512 = 5130\n",
        "\n",
        "TOTAL: 401920 + 5130 = 407050\n",
        "\n",
        "*SÉPTIMA RED NEURONAL*\n",
        "\n",
        "En la séptima red neuronal (networks[6]), tenemos un total de 407050 parámetros.\n",
        "\n",
        "Capa 1: 512 x 784 + 512 = 401920\n",
        "\n",
        "Capa 2: 512 x 10 + 512 = 5130\n",
        "\n",
        "TOTAL: 401920 + 5130 = 407050\n",
        "\n",
        "*OCTAVA RED NEURONAL*\n",
        "\n",
        "En la octava red neuronal (networks[7]), tenemos un total de 407050 parámetros.\n",
        "\n",
        "Capa 1: 512 x 784 + 512 = 401920\n",
        "\n",
        "Capa 2: 512 x 10 + 512 = 5130\n",
        "\n",
        "TOTAL: 401920 + 5130 = 407050"
      ],
      "metadata": {
        "id": "ZZ4lHsBgz54O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPwy8WFkKaMw"
      },
      "source": [
        "# 3. Analizar e interpretar los resultados del caso 2 y el 7 frente a sus originales si se multiplica por 5 las épocas de entrenamiento (25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXJwaXDwV1XR"
      },
      "source": [
        "Imprimimos los resultados del caso 2 y 7 (con 5 épocas tal y como están programados originalmente)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8_0o6pTQ8ks",
        "outputId": "afad493d-c38f-43d4-cca0-d4c50e18b4fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos red 2\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4555 - accuracy: 0.8392\n",
            "test_loss: 0.4554958939552307\n",
            "test_acc: 0.8392000198364258\n",
            "\n",
            "Datos red 7\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.7499 - accuracy: 0.7488\n",
            "test_loss: 0.7499193549156189\n",
            "test_acc: 0.7487999796867371\n",
            "\n"
          ]
        }
      ],
      "source": [
        "v = [1, 6]\n",
        "for i in v:\n",
        "  print(f'Datos red {i+1}')\n",
        "  test_loss, test_acc = networks[i].evaluate(test_images, test_labels) # la precisión es menor, pq ha perdido generalidad (sobreentrenamiento)\n",
        "  print('test_loss:', test_loss)\n",
        "  print('test_acc:', test_acc)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qd87L85WBR2"
      },
      "source": [
        "Obtenemos una 'accuracy' del 83.92% en el caso 2, y del 74.80% para el caso 7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHFvUHW0QIOR"
      },
      "source": [
        "Multiplicamos por 5 las épocas de entrenamiento y volvemos a entrenar las redes 2 y 7 con el nuevo número de épocas.\n",
        "\n",
        "De nuevo, podemos usar la función load_model para cargar las redes neuronales ya entrenadas con esas modificaciones para ahorrar tiempo."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.engine.functional import network_serialization\n",
        "from keras.models import load_model\n",
        "networks_modificadas = []\n",
        "# Especifica la ruta al archivo del modelo\n",
        "networks_path = 'trained_networks'\n",
        "# Carga el modelo\n",
        "for i in v:\n",
        "    model_path = \"/\".join([networks_path, f\"network_{i}_25_epochs\"])\n",
        "    networks_modificadas.append(load_model(model_path))"
      ],
      "metadata": {
        "id": "MJgduTht4sGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hemos creado un vector de networks modificadas, con los casos 2 y 7 modificados en cada elemento del vector."
      ],
      "metadata": {
        "id": "jNvNeOQrNYpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(networks_modificadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLUhKPB8JVWR",
        "outputId": "8e863885-c982-42f9-ebbe-6e8ac25b166c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 384
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opcionalmente las podemos entrenar para comprobar que se entrenan correctamente."
      ],
      "metadata": {
        "id": "gGL3DvrK45rU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxO9sZQpWAcf",
        "outputId": "425e4efe-da67-4a7c-8f66-a451dce90c66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.8250 - accuracy: 0.7237\n",
            "Epoch 2/25\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.5043 - accuracy: 0.8266\n",
            "Epoch 3/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4593 - accuracy: 0.8405\n",
            "Epoch 4/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4365 - accuracy: 0.8476\n",
            "Epoch 5/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4216 - accuracy: 0.8528\n",
            "Epoch 6/25\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.4106 - accuracy: 0.8560\n",
            "Epoch 7/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4026 - accuracy: 0.8592\n",
            "Epoch 8/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3954 - accuracy: 0.8614\n",
            "Epoch 9/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3891 - accuracy: 0.8637\n",
            "Epoch 10/25\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3849 - accuracy: 0.8645\n",
            "Epoch 11/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3800 - accuracy: 0.8658\n",
            "Epoch 12/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3766 - accuracy: 0.8679\n",
            "Epoch 13/25\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.3724 - accuracy: 0.8686\n",
            "Epoch 14/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3699 - accuracy: 0.8696\n",
            "Epoch 15/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3668 - accuracy: 0.8710\n",
            "Epoch 16/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3653 - accuracy: 0.8705\n",
            "Epoch 17/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3625 - accuracy: 0.8720\n",
            "Epoch 18/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.8720\n",
            "Epoch 19/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3580 - accuracy: 0.8736\n",
            "Epoch 20/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3562 - accuracy: 0.8734\n",
            "Epoch 21/25\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3544 - accuracy: 0.8746\n",
            "Epoch 22/25\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.3525 - accuracy: 0.8751\n",
            "Epoch 23/25\n",
            "469/469 [==============================] - 2s 3ms/step - loss: 0.3508 - accuracy: 0.8763\n",
            "Epoch 24/25\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3494 - accuracy: 0.8762\n",
            "Epoch 25/25\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 0.3482 - accuracy: 0.8757\n",
            "Epoch 1/25\n",
            "469/469 [==============================] - 5s 9ms/step - loss: 1.7085 - accuracy: 0.5800\n",
            "Epoch 2/25\n",
            "469/469 [==============================] - 7s 14ms/step - loss: 1.1315 - accuracy: 0.7124\n",
            "Epoch 3/25\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.9246 - accuracy: 0.7328\n",
            "Epoch 4/25\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.8220 - accuracy: 0.7436\n",
            "Epoch 5/25\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.7605 - accuracy: 0.7539\n",
            "Epoch 6/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.7185 - accuracy: 0.7611\n",
            "Epoch 7/25\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6876 - accuracy: 0.7679\n",
            "Epoch 8/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6631 - accuracy: 0.7743\n",
            "Epoch 9/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.6429 - accuracy: 0.7795\n",
            "Epoch 10/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.6261 - accuracy: 0.7848\n",
            "Epoch 11/25\n",
            "469/469 [==============================] - 5s 10ms/step - loss: 0.6115 - accuracy: 0.7897\n",
            "Epoch 12/25\n",
            "469/469 [==============================] - 4s 10ms/step - loss: 0.5986 - accuracy: 0.7935\n",
            "Epoch 13/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5874 - accuracy: 0.7975\n",
            "Epoch 14/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5770 - accuracy: 0.8009\n",
            "Epoch 15/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5680 - accuracy: 0.8048\n",
            "Epoch 16/25\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.5598 - accuracy: 0.8069\n",
            "Epoch 17/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5523 - accuracy: 0.8092\n",
            "Epoch 18/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5455 - accuracy: 0.8117\n",
            "Epoch 19/25\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.5392 - accuracy: 0.8135\n",
            "Epoch 20/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5334 - accuracy: 0.8157\n",
            "Epoch 21/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5280 - accuracy: 0.8171\n",
            "Epoch 22/25\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.5227 - accuracy: 0.8190\n",
            "Epoch 23/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5184 - accuracy: 0.8208\n",
            "Epoch 24/25\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.5142 - accuracy: 0.8225\n",
            "Epoch 25/25\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.5101 - accuracy: 0.8237\n"
          ]
        }
      ],
      "source": [
        "from keras.src.saving.saving_lib import save_model\n",
        "networks_modificadas = []\n",
        "cont=0\n",
        "for i in v:\n",
        "  networks_modificadas.append(networks[i].set_weights(initial_weights[i])) # esta linea es para entrenar por primera vez para los pesos iniciales\n",
        "  networks_modificadas[cont].fit(train_images, train_labels, epochs=25, batch_size=128)\n",
        "  cont++"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVy3FXlKXVko"
      },
      "source": [
        "Imprimimos los nuevos resultados de los casos 2 y 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL-emTN9XfoA",
        "outputId": "8f116256-3d74-4737-b4f6-d84cd5c6de84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.4247 - accuracy: 0.8535\n",
            "test_loss: 0.4246588349342346\n",
            "test_acc: 0.8535000085830688\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.5326 - accuracy: 0.8110\n",
            "test_loss: 0.5325948596000671\n",
            "test_acc: 0.8109999895095825\n"
          ]
        }
      ],
      "source": [
        "for network_m in networks_modificadas:\n",
        "  test_loss, test_acc = network_m.evaluate(test_images, test_labels)\n",
        "  print('test_loss:', test_loss)\n",
        "  print('test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqNe3IfLZJjc"
      },
      "source": [
        "Observamos que la precisión ha mejorado, al añadir más épocas, las redes neuronales se han ajustado más al set de datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYje0MGTZdZm"
      },
      "source": [
        "# 4. Evaluar cada uno de los 8 modelos comparando el rendimiento del modelo en el conjunto de datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXKlVmprZ0J7",
        "outputId": "88231284-ca84-4e31-fa7d-acc861c2c4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6203 - accuracy: 0.7817\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 0:\n",
            "test_loss: 0.6203047037124634\n",
            "test_acc: 0.7817000150680542\n",
            "313/313 [==============================] - 81s 259ms/step - loss: 0.4555 - accuracy: 0.8392\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 1:\n",
            "test_loss: 0.4554958939552307\n",
            "test_acc: 0.8392000198364258\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.2684 - accuracy: 0.6435\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 2:\n",
            "test_loss: 1.2684481143951416\n",
            "test_acc: 0.6434999704360962\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5101 - accuracy: 0.8248\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 3:\n",
            "test_loss: 0.5100712180137634\n",
            "test_acc: 0.8248000144958496\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.5239 - accuracy: 0.8247\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 4:\n",
            "test_loss: 0.5239430665969849\n",
            "test_acc: 0.8246999979019165\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.3543 - accuracy: 0.8742\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 5:\n",
            "test_loss: 0.35428786277770996\n",
            "test_acc: 0.8741999864578247\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.7499 - accuracy: 0.7488\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 6:\n",
            "test_loss: 0.7499193549156189\n",
            "test_acc: 0.7487999796867371\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.4093 - accuracy: 0.8512\n",
            "\n",
            "PARÁMETROS DE LA RED NEURONAL 7:\n",
            "test_loss: 0.4092528820037842\n",
            "test_acc: 0.8511999845504761\n"
          ]
        }
      ],
      "source": [
        "for i, network in enumerate(networks):\n",
        "  test_loss, test_acc = network.evaluate(test_images, test_labels) # la precisión es menor, pq ha perdido generalidad (sobreentrenamiento)\n",
        "  print(f\"\\nPARÁMETROS DE LA RED NEURONAL {i}:\")\n",
        "  print('test_loss:', test_loss)\n",
        "  print('test_acc:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3HA9sqGaj3h"
      },
      "source": [
        "# 5. Usar cada uno de los 8 modelos para hacer predicciones sobre la 6ª imagen de test (test_images[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos el elemento de test nº 5 (el 6 comenzando desde el 0):"
      ],
      "metadata": {
        "id": "YHyHhgQSgxUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt # TODO importar mnist, como lo hace el profe\n",
        "ropa = test_images[5]\n",
        "plt.imshow(ropa, cmap=plt.cm.binary) # Veamos el elemento 0 del set de tests y pintémoslo con matplotlib\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7cN2iMjtg3pE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "afd3a3c8-f6ab-4655-ad40-f151c6d012a0"
      },
      "execution_count": 392,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC9M1dYXlA87",
        "outputId": "3e7f2a50-bb3b-4bd4-b2a9-130adb17d9ea"
      },
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 393
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se trata de un pantalón (asociado a la etiqueta 1).\n",
        "A continuación probamos la imagen de test en las 8 redes neuronales."
      ],
      "metadata": {
        "id": "tH6AqcAilGo3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dQ0NtqROkRm"
      },
      "source": [
        "Las redes esperan un set de datos en la forma np.array de tres dimensiones, por tanto no le puedo pasar test_images[5] que es un np.array de (28, 28), es decir, dos dimensiones.\\\n",
        "En palabras simples la red espera un vector con imágenes dentro, en total espera vectores con 3 dimensiones.\\\n",
        "Para pasarle una sola imagen la tenemos que meter en un vector, que equivale a añadir una dimensión en la componente 0 (axis=0).\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8HT1eF77ZqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa9cd499-0a9b-4497-d39e-59d96c3902f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 130ms/step\n",
            "RED NEURONAL 0\n",
            "Vector de probabilidades:\n",
            "[[0.   0.97 0.   0.01 0.01 0.   0.01 0.   0.   0.  ]]\n",
            "Predicción:\n",
            "1\n",
            "\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "RED NEURONAL 1\n",
            "Vector de probabilidades:\n",
            "[[0.   0.99 0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
            "Predicción:\n",
            "1\n",
            "\n",
            "1/1 [==============================] - 0s 149ms/step\n",
            "RED NEURONAL 2\n",
            "Vector de probabilidades:\n",
            "[[0.06 0.45 0.1  0.13 0.07 0.02 0.11 0.02 0.03 0.01]]\n",
            "Predicción:\n",
            "1\n",
            "\n",
            "1/1 [==============================] - 0s 257ms/step\n",
            "RED NEURONAL 3\n",
            "Vector de probabilidades:\n",
            "[[0.   0.95 0.01 0.02 0.01 0.   0.   0.   0.   0.  ]]\n",
            "Predicción:\n",
            "1\n",
            "\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "RED NEURONAL 4\n",
            "Vector de probabilidades:\n",
            "[[0.   0.98 0.   0.   0.01 0.   0.   0.   0.   0.  ]]\n",
            "Predicción:\n",
            "1\n",
            "\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "RED NEURONAL 5\n",
            "Vector de probabilidades:\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Predicción:\n",
            "1\n",
            "\n",
            "1/1 [==============================] - 0s 171ms/step\n",
            "RED NEURONAL 6\n",
            "Vector de probabilidades:\n",
            "[[0.05 0.83 0.01 0.06 0.03 0.   0.03 0.   0.   0.  ]]\n",
            "Predicción:\n",
            "1\n",
            "\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "RED NEURONAL 7\n",
            "Vector de probabilidades:\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "Predicción:\n",
            "1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "target = np.expand_dims(test_images[5], axis=0)  # Añadimos una dimensión al np.array\n",
        "for i,network in enumerate(networks):\n",
        "  probability = networks[i].predict(target)  # Obtenemos los resultados de la capa de salida (probabilidad en cada componente)\n",
        "  prediction = np.argmax(probability)  # Tomamos como salida de la red el índice de la categoría con mayor probabilidad\n",
        "  print(f'RED NEURONAL {i}')\n",
        "  print('Vector de probabilidades:')\n",
        "  print(probability)\n",
        "  print('Predicción:')\n",
        "  print(prediction)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "De acuerdo con la etiqueta, obtenemos que todas las redes predicen que la imagen introducida es un pantalón (etiqueta 1)."
      ],
      "metadata": {
        "id": "0dUxWz3allKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Gráficas de los 8 modelos"
      ],
      "metadata": {
        "id": "AKzZ8KOdc8-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "graficamos cómo de bien o de mal se comporta el\n",
        "modelo para cada uno de los 8 casos."
      ],
      "metadata": {
        "id": "E1j5KLHSdHS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label.all() == true_label.all():\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n",
        "                                100*np.max(predictions_array),\n",
        "                                true_label),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#7777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ],
      "metadata": {
        "id": "brN84uRvdvR4"
      },
      "execution_count": 394,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "predictions = network.predict(test_images)\n",
        "\n",
        "for i in range(20):\n",
        "  plt.figure(figsize=(6,3))\n",
        "  plt.subplot(1,2,1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images.reshape(10000,28,28))\n",
        "  plt.subplot(1,2,2)\n",
        "  plot_value_array(i, predictions[i],  test_labels)\n",
        "  plt.show()\n",
        "  plt.clf()"
      ],
      "metadata": {
        "id": "Fo0-zM-vmNgr",
        "outputId": "edeb57c9-4a82-461b-b45c-430ffcc25889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        }
      },
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "313/313 [==============================] - 2s 5ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-395-1e5d34fd6b3c>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mplot_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mplot_value_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-394-f4b04c17438d>\u001b[0m in \u001b[0;36mplot_value_array\u001b[0;34m(i, predictions_array, true_label)\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mthisplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"#7777777\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2437\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'center'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2438\u001b[0m         data=None, **kwargs):\n\u001b[0;32m-> 2439\u001b[0;31m     return gca().bar(\n\u001b[0m\u001b[1;32m   2440\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2441\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mbar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2439\u001b[0m         \u001b[0mlinewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinewidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m         \u001b[0mhatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2441\u001b[0;31m         color = itertools.chain(itertools.cycle(mcolors.to_rgba_array(color)),\n\u001b[0m\u001b[1;32m   2442\u001b[0m                                 \u001b[0;31m# Fallback if color == \"none\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m                                 itertools.repeat('none'))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/colors.py\u001b[0m in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{c!r} is not a valid color value.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: '#7777777' is not a valid color value."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ-feL8CbK2I"
      },
      "source": [
        "# 7. Mejoras al modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cfuHEA2cAJu"
      },
      "source": [
        "Usando el de la configuración del caso 3, pero cambiando el\n",
        "optimizador por ‘adam’ y la función de pérdida ‘sparse_categorical_crossentropy’. Buscar en internet las bases de dicho optimizador y función de pérdida, explícalos con tus propias palabras y plantea tus reflexiones respecto al resultado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK2s2NamcU24"
      },
      "source": [
        "Usaremos la red neuronal 2 (la 3 empezando a contar desde 0), pero con cambios en optimizador y la función de pérdida.\n",
        "* `adam`\n",
        "* `sparse_categorical_crossentropy`\n",
        "\n",
        "**Adam** es un optimizador que combina conceptos de RMSprop y Momentum, manteniendo dos momentos para cada parámetro. Estos momentos permiten que Adam ajuste dinámicamente la tasa de aprendizaje para cada parámetro, adaptándose bien a diferentes conjuntos de datos y arquitecturas de red. La capacidad de Adam para adaptarse automáticamente y su eficiencia en la práctica lo hacen ampliamente utilizado en la optimización de redes neuronales.\n",
        "\n",
        "**sparse_categorical_crossentropy** es una función de pérdida utilizada comúnmente en problemas de clasificación donde las etiquetas son enteros en lugar de codificación one-hot. En lugar de requerir que las etiquetas de destino sean un vector categórico, como en categorical_crossentropy, esta función acepta enteros que representan las clases. Es eficiente y evita la necesidad de convertir las etiquetas en codificación one-hot, simplificando así el proceso. La función calcula la pérdida entre las distribuciones de probabilidad predichas y las etiquetas, siendo adecuada para problemas de clasificación con varias clases donde cada instancia pertenece a una única clase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYetFV6YdbHA"
      },
      "outputs": [],
      "source": [
        "networks[2].compile(optimizer='adam',\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARJIFLX16_4c"
      },
      "source": [
        "Entrenamos la red con los nuevos cambios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPwkGqwg7EQs",
        "outputId": "84869fa4-ada1-4b44-dfd8-b78e2f401e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 2.1152 - accuracy: 0.3309\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.8197 - accuracy: 0.5405\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.6128 - accuracy: 0.5920\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.4494 - accuracy: 0.6216\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 1s 2ms/step - loss: 1.3178 - accuracy: 0.6395\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c04de9ea6e0>"
            ]
          },
          "metadata": {},
          "execution_count": 391
        }
      ],
      "source": [
        "networks[2].set_weights(initial_weights[2])                           # inicializamos los pesos, para no reutilizar los del entrenamiento anterior\n",
        "networks[2].fit(train_images, train_labels, epochs=5, batch_size=128)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}